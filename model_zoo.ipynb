{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fad1e13",
   "metadata": {},
   "source": [
    "# Model Zoo\n",
    "- Model test code for LatentForce VoiceStudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850bb62",
   "metadata": {},
   "source": [
    "## 0. Common Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d904d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"INFO: Using device -\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90805fbc",
   "metadata": {},
   "source": [
    "## 1. Parler TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from voicestudio.models.parler_tts import ParlerTTSForConditionalGeneration\n",
    "\n",
    "\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-mini-v1\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-mini-v1\")\n",
    "\n",
    "prompt = \"Hey, how are you doing today?\"\n",
    "description = \"Jon's voice is monotone yet slightly fast in delivery, with a very close recording that almost has no background noise.\"\n",
    "\n",
    "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "audio_arr = generation.cpu().numpy().squeeze()\n",
    "sf.write(\"parler_tts_out.wav\", audio_arr, model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae3366",
   "metadata": {},
   "source": [
    "## 2. Higgs Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b07f9",
   "metadata": {},
   "source": [
    "## 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdec980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, DiaForConditionalGeneration\n",
    "\n",
    "\n",
    "torch_device = \"cuda\"\n",
    "model_checkpoint = \"nari-labs/Dia-1.6B-0626\"\n",
    "\n",
    "text = [\n",
    "    \"[S1] Dia is an open weights text to dialogue model. [S2] You get full control over scripts and voices. [S1] Wow. Amazing. (laughs) [S2] Try it now on Git hub or Hugging Face.\"\n",
    "]\n",
    "processor = AutoProcessor.from_pretrained(model_checkpoint)\n",
    "inputs = processor(text=text, padding=True, return_tensors=\"pt\").to(torch_device)\n",
    "\n",
    "model = DiaForConditionalGeneration.from_pretrained(model_checkpoint).to(torch_device)\n",
    "outputs = model.generate(\n",
    "    **inputs, max_new_tokens=3072, guidance_scale=3.0, temperature=1.8, top_p=0.90, top_k=45\n",
    ")\n",
    "\n",
    "outputs = processor.batch_decode(outputs)\n",
    "processor.save_audio(outputs, \"example.mp3\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
