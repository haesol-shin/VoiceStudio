{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81619054298cb84",
   "metadata": {},
   "source": [
    "# Interspeech 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678cda37dd5de34",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from transformers.utils.notebook import NotebookProgressBar\n",
    "\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from voicestudio.utils.audio_utils import show_waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4c9ee916b8505",
   "metadata": {},
   "source": [
    "### Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9a659920805ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7cad9ff7ebd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "device_map = f\"cuda:{DEVICE_NUM}\" if DEVICE_NUM >= 0 else \"cpu\"\n",
    "print(f\"INFO: Using device - {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca176a8586463d",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f3f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spk_incon.datasets import LIBRITTS_P_Custom\n",
    "from spk_incon.datasets.libritts_p3 import download_libritts_p_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27465f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"./data\"\n",
    "URL = \"https://dolab-data.duckdns.org/api/public/dl/-qA96ilN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(os.path.join(DATA_ROOT, \"train-clean-100.tar.gz\")):\n",
    "    !wget -O \"./data/train-clean-100.tar.gz\" {URL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    curated_dataset = LIBRITTS_P_Custom(root=DATA_ROOT, download=False)\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        download_libritts_p_metadata(root=DATA_ROOT)\n",
    "        curated_dataset = LIBRITTS_P_Custom(root=DATA_ROOT, download=False)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Full download logic triggered. This may take a while...\")\n",
    "        curated_dataset = LIBRITTS_P_Custom(root=DATA_ROOT, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36a00b89ab989e",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936726a74275f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoProcessor\n",
    "\n",
    "from voicestudio.models.qwen3_tts import Qwen3TTSForConditionalGeneration\n",
    "from spk_incon.models.selective_tuner import SelectiveTunerForConditionalGeneration, SelectiveTunerConfig\n",
    "from spk_incon.components.style_anchor import DirectStyleAnchorEmbedding, EncoderStyleAnchorEmbedding, MixedStyleAnchorEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Qwen3TTSForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device_map,\n",
    "    dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id, device_map=device_map)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f132c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_config = model.config.to_dict()\n",
    "print(\"Original Model Config:\")\n",
    "for key, value in original_config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296b9ffddaac0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Inference\n",
    "inputs = processor.encode_voice_design(\n",
    "    text=\"I am solving the equation: x = [-b ± √(b²-4ac)] / 2a? Nobody can — it's a disaster (◍•͈⌔•͈◍), very sad!\",\n",
    "    instruct=\"Happy man describes the equation in a cheerful tone, with a hint of humor. He emphasizes the complexity of the equation and expresses his feelings about it in a lighthearted way.\",\n",
    ")\n",
    "outputs = model.generate(**inputs)\n",
    "\n",
    "audio_values, sr = processor.decode(outputs)\n",
    "show_waveform(None, waveform=torch.from_numpy(audio_values[0]), sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77413e05c2bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = SelectiveTunerConfig.from_pretrained(\n",
    "#    model.config,\n",
    "#    anchor_token=(tuple(), (\"<consistency>\", )), anchor_token_id=((1, ), (len(processor.tokenizer), )), use_direct_anchor=False, tie_embeddings=True\n",
    "#)\n",
    "#setattr(config, 'hidden_size', config.decoder.hidden_size)  # parler-tts doesn't have decoder hidden_size conf\n",
    "#config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SelectiveTunerConfig.from_pretrained(\n",
    "    model.config,\n",
    "    anchor_token=(\"<consistency>\", ), anchor_token_id=(len(processor.tokenizer), ), use_direct_anchor=False, tie_embeddings=True\n",
    ")\n",
    "#setattr(config, 'hidden_size', config.decoder.hidden_size)  # parler-tts doesn't have decoder hidden_size conf\n",
    "#config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f727543",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.talker_config.text_vocab_size, config.talker_config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(config, 'vocab_size', config.talker_config.text_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(config, 'hidden_size', config.talker_config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fff9943384029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectiveTunerForConditionalGeneration._replace_embeddings_with_anchors(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectiveTunerForConditionalGeneration.extend_vocabulary(model, processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25823001cc14ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for module in model.modules():\n",
    "    if isinstance(module, (DirectStyleAnchorEmbedding, EncoderStyleAnchorEmbedding, MixedStyleAnchorEmbedding)):\n",
    "        print(f\"INFO: Found a target embedding instance: {type(module).__name__}\")\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292041e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb88bf80e4e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf76648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model still works after modification\n",
    "inputs = processor.encode_voice_design(\n",
    "    text=\"I am solving the equation: x = [-b ± √(b²-4ac)] / 2a? Nobody can — it's a disaster (◍•͈⌔•͈◍), very sad!\",\n",
    "    instruct=\"Happy man describes the equation in a cheerful tone, with a hint of humor. He emphasizes the complexity of the equation and expresses his feelings about it in a lighthearted way.\",\n",
    ")\n",
    "outputs = model.generate(**inputs)\n",
    "\n",
    "audio_values, sr = processor.decode(outputs)\n",
    "show_waveform(None, waveform=torch.from_numpy(audio_values[0]), sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375568c6ddc2059",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cafc886d53d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 2\n",
    "LEARNING_RATE = 1e-4\n",
    "OUTPUT_DIR = \"./results/consistency\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb09013cf19fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW([p for p in model.parameters() if p.requires_grad], lr=LEARNING_RATE, weight_decay=0.01)\n",
    "total_steps = len(dataset) * NUM_EPOCHS\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=LEARNING_RATE/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbbdc141ae2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bar = NotebookProgressBar(NUM_EPOCHS, prefix=\"Running Epochs\")\n",
    "for epoch in range(0, NUM_EPOCHS):\n",
    "    total_bar.update(epoch+1)\n",
    "    train_loss, train_mfcc = [], []\n",
    "\n",
    "    train_loader, train_len = load_data_by_epoch(epoch)\n",
    "\n",
    "    train_bar = NotebookProgressBar(int(train_len/BATCH_SIZE+0.99), prefix=f\"Training {epoch+1}\")\n",
    "    for i, inputs in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        try:\n",
    "            outputs = trainer(\n",
    "                style_prompts=inputs['style'],\n",
    "                transcriptions_1=inputs['content1'],\n",
    "                transcriptions_2=inputs['content2'],\n",
    "            )\n",
    "        except (torch.cuda.OutOfMemoryError, RuntimeError):\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "        losses = outputs['loss']\n",
    "        #mfcc = outputs['mfcc_consistency_loss']\n",
    "\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss.append(losses.item())\n",
    "\n",
    "        if i+1 != train_bar.total: train_bar.update(i+1, comment=f\"Loss={losses.item():.5f}, LR={optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "    torch.save(model.state_dict(), OUTPUT_DIR+f\"/epoch{epoch+1}.pt\")\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    train_bar.update(train_bar.total, comment=f\"Loss={sum(train_loss)/len(train_loss):.5f}, LR={optimizer.param_groups[0]['lr']:.1e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "copied = copy.deepcopy(model).cpu()\n",
    "copied.merge_and_unload(cast_to_embedding=True)\n",
    "copied.save_pretrained(OUTPUT_DIR+\"_final\")\n",
    "del copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(OUTPUT_DIR+\"_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40018af7",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spk_incon.metrics.presets import DatasetType, GenerationMethod, SynthesisConfig, ModelType\n",
    "from spk_incon.metrics.strategies import create_strategy\n",
    "from spk_incon.datasets import DatasetType, create_dataset\n",
    "\n",
    "from spk_incon.utils.evaluate import EvaluationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = SynthesisConfig()\n",
    "test_dataset_type = DatasetType.LIBRITTS\n",
    "test_dataset_config = test_config.get_dataset_config(test_dataset_type.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_dataset(test_dataset_type, test_dataset_config, root_dir=\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "class TestModel:\n",
    "    @classmethod\n",
    "    def seed_everything(cls, seed: int = 42):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    @classmethod\n",
    "    def synthesize(\n",
    "        cls,\n",
    "        text: str,\n",
    "        output_path: Path,\n",
    "        reference_audio: Path | None = None,\n",
    "        style_prompt: str | None = None,\n",
    "        speaker_id: str | None = None\n",
    "    ) -> bool:\n",
    "        cls.seed_everything()\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        #description_ids = tokenizer(style_prompt, return_tensors=\"pt\").input_ids\n",
    "        #text_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "        \n",
    "        # Example Inference\n",
    "        inputs = processor.encode_voice_design(\n",
    "            text=text,\n",
    "            instruct=style_prompt,\n",
    "        )\n",
    "        outputs = model.generate(**inputs)\n",
    "\n",
    "        audio_values, sr = processor.decode(outputs)\n",
    "        sf.write(output_path, audio_values[0], sr)\n",
    "\n",
    "        #with torch.inference_mode():\n",
    "        #    audio = model.generate(\n",
    "        #        input_ids=description_ids.to(device),\n",
    "        #        prompt_input_ids=text_ids.to(device),\n",
    "        #        #top_k=1,\n",
    "        #    )\n",
    "\n",
    "        #sf.write(output_path, audio.cpu().numpy().squeeze(), sample_rate)\n",
    "\n",
    "        try:\n",
    "            return output_path.stat().st_size > 0\n",
    "        except FileNotFoundError:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_type = ModelType.PARLER_TTS_MINI_V1\n",
    "test_model = TestModel()\n",
    "\n",
    "evaluator = EvaluationPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e996005",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = create_strategy(GenerationMethod.METHOD1, test_config, test_dataset, test_model)\n",
    "exp1_result = strategy.generate_all(test_dataset_type.value, test_model_type.value)\n",
    "exp1_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_eval_result = evaluator.evaluate_dataset_model(\n",
    "    dataset_type=test_dataset_type,\n",
    "    model_type=test_model_type,\n",
    "    methods=[GenerationMethod.METHOD1]\n",
    ")\n",
    "evaluator.save_results_to_csv(exp1_eval_result, test_dataset_type, test_model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917882d7",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ca4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = create_strategy(GenerationMethod.METHOD2, test_config, test_dataset, test_model)\n",
    "exp2_result = strategy.generate_all(test_dataset_type.value, test_model_type.value)\n",
    "exp2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb1866",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_eval_result = evaluator.evaluate_dataset_model(\n",
    "    dataset_type=test_dataset_type,\n",
    "    model_type=test_model_type,\n",
    "    methods=[GenerationMethod.METHOD2]\n",
    ")\n",
    "evaluator.save_results_to_csv(exp2_eval_result, test_dataset_type, test_model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43016740",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e83ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = create_strategy(GenerationMethod.METHOD3, test_config, test_dataset, test_model)\n",
    "exp3_result = strategy.generate_all(test_dataset_type.value, test_model_type.value)\n",
    "exp3_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e1f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp3_eval_result = evaluator.evaluate_dataset_model(\n",
    "    dataset_type=test_dataset_type,\n",
    "    model_type=test_model_type,\n",
    "    methods=[GenerationMethod.METHOD3]\n",
    ")\n",
    "evaluator.save_results_to_csv(exp3_eval_result, test_dataset_type, test_model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136bc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spk-incon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
