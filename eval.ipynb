{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81619054298cb84",
   "metadata": {},
   "source": [
    "# Interspeech 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678cda37dd5de34",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from transformers.utils.notebook import NotebookProgressBar\n",
    "\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from voicestudio.utils.audio_utils import show_waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4c9ee916b8505",
   "metadata": {},
   "source": [
    "### Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9a659920805ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7cad9ff7ebd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "device_map = f\"cuda:{DEVICE_NUM}\" if DEVICE_NUM >= 0 else \"cpu\"\n",
    "print(f\"INFO: Using device - {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36a00b89ab989e",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45874f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoProcessor\n",
    "\n",
    "from voicestudio.models.parler_tts import ParlerTTSForConditionalGeneration\n",
    "from voicestudio.models.qwen3_tts import Qwen3TTSForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936726a74275f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spk_incon.models.selective_tuner import SelectiveTunerForConditionalGeneration, SelectiveTunerConfig\n",
    "from spk_incon.components.style_anchor import DirectStyleAnchorEmbedding, EncoderStyleAnchorEmbedding, MixedStyleAnchorEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e378ac9",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model select\n",
    "#model_id = \"parler-tts/parler-tts-mini-v1\"\n",
    "#model_id = \"parler-tts/parler-tts-large-v1\"\n",
    "#model_id = \"parler-tts/parler-tts-mini-v1.1\"\n",
    "\n",
    "#model_id = \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\"\n",
    "model_id = \"Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model loading\n",
    "if \"parler\" in model_id.lower():\n",
    "    model = ParlerTTSForConditionalGeneration.from_pretrained(\n",
    "        model_id, device_map=device_map\n",
    "    )\n",
    "    config = model.config\n",
    "    model_dtype = model.dtype\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "elif \"qwen\" in model_id.lower():\n",
    "    model = Qwen3TTSForConditionalGeneration.from_pretrained(\n",
    "        model_id, device_map=device_map, dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\",\n",
    "    )\n",
    "    config = model.config\n",
    "    model_dtype = model.dtype\n",
    "    processor = AutoProcessor.from_pretrained(model_id, device_map=device_map)\n",
    "    tokenizer = processor.tokenizer\n",
    "else:\n",
    "    pass\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c3f2d",
   "metadata": {},
   "source": [
    "### Embedding-tuner Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246205fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode settings\n",
    "USING_STRUCT_A = False  # if false prompt template struct B will be used\n",
    "\n",
    "print(f\"BOS token: {tokenizer.bos_token}, ID: {tokenizer.bos_token_id}\")\n",
    "print(f\"EOS token: {tokenizer.eos_token}, ID: {tokenizer.eos_token_id}\")\n",
    "print(f\"PAD token: {tokenizer.pad_token}, ID: {tokenizer.pad_token_id}\")\n",
    "\n",
    "im_start_id = tokenizer.convert_tokens_to_ids(\"<|im_start|>\")\n",
    "im_end_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "\n",
    "print(f\"<|im_start|> token_id: {im_start_id}\")\n",
    "print(f\"<|im_end|> token_id: {im_end_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token definitions\n",
    "STYLE_TOKEN = \"<|style|>\"\n",
    "STYLE_TOKEN_ID = len(tokenizer)\n",
    "CONSISTENCY_TOKEN = \"<|consistency|>\"\n",
    "CONSISTENCY_TOKEN_ID = len(tokenizer) + 1\n",
    "\n",
    "anchor_token = STYLE_TOKEN, CONSISTENCY_TOKEN\n",
    "anchor_token_id = STYLE_TOKEN_ID, CONSISTENCY_TOKEN_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe86b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "OUTPUT_DIR = path.join(\".\", \"results\", f\"model_id_epoch{1}_iter{99}\")\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model weight loading\n",
    "from safetensors.torch import load_file\n",
    "model.load_state_dict(load_file(OUTPUT_DIR + \"/model.safetensors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend vocabulary\n",
    "num_added = tokenizer.add_tokens(list(anchor_token))\n",
    "assert STYLE_TOKEN_ID == tokenizer.convert_tokens_to_ids(STYLE_TOKEN)\n",
    "assert CONSISTENCY_TOKEN_ID == tokenizer.convert_tokens_to_ids(CONSISTENCY_TOKEN)\n",
    "print(f\"INFO: Added {num_added} anchor tokens to tokenizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf76648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model still works after modification\n",
    "if \"parler\" in model_id.lower():\n",
    "    prompt = \"Hey, how are you doing today?\"\n",
    "    #description = \"Jon's voice is monotone yet slightly fast in delivery, with a very close recording that almost has no background noise.\"\n",
    "    description = \"A female speaker delivers a slightly expressive and animated speech with a moderate speed and pitch. The recording is of very high quality, with the speaker's voice sounding clear and very close up.\"\n",
    "    input_ids, prompt_input_ids = (tokenizer(d, return_tensors=\"pt\").input_ids.to(device) for d in [description, prompt])\n",
    "\n",
    "    outputs = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "    audio_values, sr = outputs.cpu().squeeze(), model.config.sampling_rate\n",
    "elif \"qwen\" in model_id.lower():\n",
    "    inputs = processor.encode_voice_design(\n",
    "        text=\"I am solving the equation: x = [-b ± √(b²-4ac)] / 2a? Nobody can — it's a disaster (◍•͈⌔•͈◍), very sad!\",\n",
    "        instruct=\"Happy man describes the equation in a cheerful tone, with a hint of humor. He emphasizes the complexity of the equation and expresses his feelings about it in a lighthearted way.\",\n",
    "    )\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "    audio_values, sr = processor.decode(outputs)\n",
    "    audio_values = torch.from_numpy(audio_values[0])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "show_waveform(None, waveform=audio_values, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebf3893",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def apply_user_promt(instruct: str, apply: bool = False):\n",
    "    return f\"<|im_start|>user\\n{instruct}<|im_end|>{STYLE_TOKEN}\\n\"\n",
    "\n",
    "def apply_assistant_prompt(text: str, sim: bool = False):\n",
    "    if not sim:\n",
    "        return f\"<|im_start|>assistant\\n{text}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    elif USING_STRUCT_A:\n",
    "        return f\"<|im_start|>assistant\\n{text}<|im_end|>\\n{CONSISTENCY_TOKEN}<|im_start|>assistant\\n\"\n",
    "    else:\n",
    "        return f\"{CONSISTENCY_TOKEN}<|im_start|>assistant\\n{text}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "\n",
    "if \"qwen\" in model_id.lower():\n",
    "    processor._build_assistant_text = partial(apply_assistant_prompt, sim=True)\n",
    "    processor._build_instruct_text = partial(apply_user_promt, apply=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40018af7",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spk_incon.metrics.presets import DatasetType, GenerationMethod, SynthesisConfig, ModelType\n",
    "from spk_incon.metrics.strategies import create_strategy\n",
    "from spk_incon.datasets import DatasetType, create_dataset\n",
    "\n",
    "from spk_incon.utils.evaluate import EvaluationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = SynthesisConfig()\n",
    "test_dataset_type = DatasetType.LIBRITTS\n",
    "test_dataset_config = test_config.get_dataset_config(test_dataset_type.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_dataset(test_dataset_type, test_dataset_config, root_dir=\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "class TestModel:\n",
    "    @classmethod\n",
    "    def seed_everything(cls, seed: int = 42):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    @classmethod\n",
    "    def synthesize(\n",
    "        cls,\n",
    "        text: str,\n",
    "        output_path: Path,\n",
    "        reference_audio: Path | None = None,\n",
    "        style_prompt: str | None = None,\n",
    "        speaker_id: str | None = None\n",
    "    ) -> bool:\n",
    "        cls.seed_everything()\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Setup generation config\n",
    "        generation_config = dict(\n",
    "            #top_k=1,\n",
    "        )\n",
    "\n",
    "        # Input preparation\n",
    "        if \"parler\" in model_id.lower():\n",
    "            inputs = dict(\n",
    "                input_ids=tokenizer(style_prompt, return_tensors=\"pt\").input_ids.to(device),\n",
    "                prompt_input_ids=tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "            )\n",
    "        elif \"qwen\" in model_id.lower():\n",
    "            inputs = processor.encode_voice_design(\n",
    "                text=text, instruct=style_prompt,\n",
    "            )\n",
    "\n",
    "        # Generation\n",
    "        outputs = model.generate(**inputs, **generation_config)\n",
    "\n",
    "        # Decoding\n",
    "        if \"parler\" in model_id.lower():\n",
    "            audio_values = outputs.cpu().numpy().squeeze()\n",
    "            sample_rate = config.audio_encoder.sampling_rate\n",
    "        elif \"qwen\" in model_id.lower():\n",
    "            audio_values, sample_rate = processor.decode(outputs)\n",
    "            audio_values = audio_values[0]\n",
    "\n",
    "        # Save audio\n",
    "        sf.write(output_path, audio_values, sample_rate)\n",
    "        try:\n",
    "            return output_path.stat().st_size > 0\n",
    "        except FileNotFoundError:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ModelType(Enum):\n",
    "    TEST = model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "test_model_type = ModelType.TEST\n",
    "test_model = TestModel()\n",
    "\n",
    "evaluator = EvaluationPipeline(base_dir=OUTPUT_DIR)\n",
    "test_config.generation.output_dir = Path(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917882d7",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ca4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = create_strategy(GenerationMethod.METHOD2, test_config, test_dataset, test_model)\n",
    "exp2_result = strategy.generate_all(test_dataset_type.value, test_model_type.value)\n",
    "exp2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb1866",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_eval_result = evaluator.evaluate_dataset_model(\n",
    "    dataset_type=test_dataset_type,\n",
    "    model_type=test_model_type,\n",
    "    methods=[GenerationMethod.METHOD2]\n",
    ")\n",
    "evaluator.save_results_to_csv(exp2_eval_result, test_dataset_type, test_model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e996005",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = create_strategy(GenerationMethod.METHOD1, test_config, test_dataset, test_model)\n",
    "exp1_result = strategy.generate_all(test_dataset_type.value, test_model_type.value)\n",
    "exp1_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_eval_result = evaluator.evaluate_dataset_model(\n",
    "    dataset_type=test_dataset_type,\n",
    "    model_type=test_model_type,\n",
    "    methods=[GenerationMethod.METHOD1]\n",
    ")\n",
    "evaluator.save_results_to_csv(exp1_eval_result, test_dataset_type, test_model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43016740",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e83ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = create_strategy(GenerationMethod.METHOD3, test_config, test_dataset, test_model)\n",
    "exp3_result = strategy.generate_all(test_dataset_type.value, test_model_type.value)\n",
    "exp3_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e1f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp3_eval_result = evaluator.evaluate_dataset_model(\n",
    "    dataset_type=test_dataset_type,\n",
    "    model_type=test_model_type,\n",
    "    methods=[GenerationMethod.METHOD3]\n",
    ")\n",
    "evaluator.save_results_to_csv(exp3_eval_result, test_dataset_type, test_model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136bc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spk-incon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
